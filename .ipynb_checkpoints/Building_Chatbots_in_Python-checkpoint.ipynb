{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbots 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EchoBot I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can hear you! You said: hello!\n"
     ]
    }
   ],
   "source": [
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that responds to a user's message: respond\n",
    "def respond(message):\n",
    "    # Concatenate the user's message to the end of a standard bot respone\n",
    "    bot_message = \"I can hear you! You said: \" + message\n",
    "    # Return the result\n",
    "    return bot_message\n",
    "\n",
    "# Test function\n",
    "print(respond(\"hello!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EchoBot II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello\n",
      "BOT : I can hear you! You said: hello\n"
     ]
    }
   ],
   "source": [
    "# Create templates\n",
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "# Send a message to the bot\n",
    "send_message(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chitchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "name = \"Greg\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary with the predefined responses\n",
    "responses = {\n",
    "  \"what's your name?\": \"my name is {0}\".format(name),\n",
    "  \"what's today's weather?\": \"the weather is {0}\".format(weather),\n",
    "  \"default\": \"default message\"\n",
    "}\n",
    "\n",
    "# Return the matching response if there is one, default otherwise\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return the matching message\n",
    "        bot_message = responses[message]\n",
    "    else:\n",
    "        # Return the \"default\" message\n",
    "        bot_message =responses[\"default\"]\n",
    "    return bot_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the random module\n",
    "import random\n",
    "\n",
    "name = \"Greg\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary containing a list of responses for each message\n",
    "responses = {\n",
    "  \"what's your name?\": [\n",
    "      \"my name is {0}\".format(name),\n",
    "      \"they call me {0}\".format(name),\n",
    "      \"I go by {0}\".format(name)\n",
    "   ],\n",
    "  \"what's today's weather?\": [\n",
    "      \"the weather is {0}\".format(weather),\n",
    "      \"it's {0} today\".format(weather)\n",
    "    ],\n",
    "  \"default\": [\"default message\"]\n",
    "}\n",
    "\n",
    "# Use random.choice() to choose a matching response\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return a random matching response\n",
    "        bot_message = random.choice(responses[message])\n",
    "    else:\n",
    "        # Return a random \"default\" response\n",
    "        bot_message = random.choice(responses[\"default\"])\n",
    "    return bot_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA I: asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : what's today's weather?\n",
      "BOT : you tell me!\n",
      "USER : what's today's weather?\n",
      "BOT : I don't know :(\n",
      "USER : I love building chatbots\n",
      "BOT : :)\n",
      "USER : I love building chatbots\n",
      "BOT : why do you think that?\n"
     ]
    }
   ],
   "source": [
    "responses = {'question': [\"I don't know :(\", 'you tell me!'], \n",
    "             'statement': ['tell me more!', 'why do you think that?', 'how long have you felt this way?', 'I find that extremely interesting', 'can you back that up?', 'oh wow!', ':)']}\n",
    "import random\n",
    "\n",
    "def respond(message):\n",
    "    # Check for a question mark\n",
    "    if message.endswith('?'):\n",
    "        # Return a random question\n",
    "        return random.choice(responses[\"question\"])\n",
    "    # Return a random statement\n",
    "    return random.choice(responses['statement'])\n",
    "\n",
    "\n",
    "# Send messages ending in a question mark\n",
    "send_message(\"what's today's weather?\")\n",
    "send_message(\"what's today's weather?\")\n",
    "\n",
    "# Send messages which don't end with a question mark\n",
    "send_message(\"I love building chatbots\")\n",
    "send_message(\"I love building chatbots\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA II: Extracting key phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {'if (.*)': [\"Do you really think it's likely that {0}\", 'Do you wish that {0}', 'What do you think about {0}', 'Really--if {0}'], \n",
    "         'I want (.*)': ['What would it mean if you got {0}', 'Why do you want {0}', \"What's stopping you from getting {0}\"], \n",
    "         'do you think (.*)': ['if {0}? Absolutely.', 'No chance'], \n",
    "         'do you remember (.*)': ['Did you think I would forget {0}', \"Why haven't you been able to forget {0}\", 'What about {0}', 'Yes .. and?']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes .. and?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define match_rule()\n",
    "def match_rule(rules, message):\n",
    "    response, phrase = \"default\", None\n",
    "    \n",
    "    # Iterate over the rules dictionary\n",
    "    for pattern, responses in rules.items():\n",
    "        # Create a match object\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            # Choose a random response\n",
    "            response = random.choice(responses)\n",
    "            if '{0}' in response:\n",
    "                phrase = match.group(1)\n",
    "    # Return the response and phrase\n",
    "    return response.format(phrase)\n",
    "\n",
    "# Test match_rule\n",
    "print(match_rule(rules, \"do you remember your last birthday\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA III: Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your last birthday\n",
      "when me went to florida\n",
      "i had your own castle\n"
     ]
    }
   ],
   "source": [
    "# Define replace_pronouns()\n",
    "def replace_pronouns(message):\n",
    "\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return re.sub('me', 'you', message)\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return re.sub('my', 'your', message)\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return re.sub('your', 'my', message)\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return re.sub('you', 'me', message)\n",
    "\n",
    "    return message\n",
    "\n",
    "print(replace_pronouns(\"my last birthday\"))\n",
    "print(replace_pronouns(\"when you went to Florida\"))\n",
    "print(replace_pronouns(\"I had my own castle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIZA IV: Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_rule(rules, message):\n",
    "    for pattern, responses in rules.items():\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            response = random.choice(responses)\n",
    "            var = match.group(1) if '{0}' in response else None\n",
    "            return response, var\n",
    "    return \"default\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : do you remember your last birthday\n",
      "BOT : What about my last birthday\n",
      "USER : do you think humans should be worried about AI\n",
      "BOT : if humans should be worried about ai? Absolutely.\n",
      "USER : I want a robot friend\n",
      "BOT : What's stopping you from getting a robot friend\n",
      "USER : what if you could be anything you wanted\n",
      "BOT : Do you really think it's likely that me could be anything me wanted\n"
     ]
    }
   ],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Call match_rule\n",
    "    response, phrase = match_rule(rules, message)\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns in the phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Include the phrase in the response\n",
    "        response = response.format(phrase)\n",
    "    return response\n",
    "\n",
    "# Send the messages\n",
    "send_message(\"do you remember your last birthday\")\n",
    "send_message(\"do you think humans should be worried about AI\")\n",
    "send_message(\"I want a robot friend\")\n",
    "send_message(\"what if you could be anything you wanted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding natural language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent classification with regex I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {'thankyou': ['thank', 'thx'], 'greet': ['hello', 'hi', 'hey'], 'goodbye': ['bye', 'farewell']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thankyou': re.compile('thank|thx'), 'greet': re.compile('hello|hi|hey'), 'goodbye': re.compile('bye|farewell')}\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(keys))\n",
    "    \n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent classification with regex II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {'thankyou': 'you are very welcome', 'greet': 'Hello you! :)', 'goodbye': 'goodbye for now', 'default': 'default message'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello!\n",
      "BOT : Hello you! :)\n",
      "USER : bye byeee\n",
      "BOT : goodbye for now\n",
      "USER : thanks very much!\n",
      "BOT : you are very welcome\n"
     ]
    }
   ],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if re.search(pattern, message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent\n",
    "\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity extraction with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : my name is David Copperfield\n",
      "BOT : Hello, David Copperfield!\n",
      "USER : call me Ishmael\n",
      "BOT : Hello, Ishmael!\n",
      "USER : People call me Cassandra\n",
      "BOT : Hello, People Cassandra!\n"
     ]
    }
   ],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile('|'.join([\"name\", \"call\"]))\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.findall('[A-Z]{1}[a-z]*', message)\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Ishmael\")\n",
    "send_message(\"People call me Cassandra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word vectors with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning', ' what flights are available from pittsburgh to baltimore on thursday morning', ' what is the arrival time in san francisco for the 755 am flight leaving washington', ' cheapest airfare from tacoma to orlando', ' round trip fares from pittsburgh to philadelphia under 1000 dollars', ' i need a flight tomorrow from columbus to minneapolis', ' what kind of aircraft is used on a flight from cleveland to dallas', ' show me the flights from pittsburgh to los angeles on thursday', ' all flights from boston to washington', ' what kind of ground transportation is available in denver', ' show me the flights from dallas to san francisco', ' show me the flights from san diego to newark by way of houston', ' what is the cheapest flight from boston to bwi', ' all flights to baltimore after 6 pm', ' show me the first class fares from boston to denver', ' show me the ground transportation in denver', ' all flights from denver to pittsburgh leaving after 6 pm and before 7 pm', ' i need information on flights for tuesday leaving baltimore for dallas dallas to boston and boston to baltimore', ' please give me the flights from boston to pittsburgh on thursday of next week', ' i would like to fly from denver to pittsburgh on united airlines', ' show me the flights from san diego to newark', ' please list all first class flights on united from denver to baltimore', ' what kinds of planes are used by american airlines', \" i'd like to have some information on a ticket from denver to pittsburgh and atlanta\", \" i'd like to book a flight from atlanta to denver\", ' which airline serves denver pittsburgh and atlanta', \" show me all flights from boston to pittsburgh on wednesday of next week which leave boston after 2 o'clock pm\", ' atlanta ground transportation', ' i also need service from dallas to boston arriving by noon', ' show me the cheapest round trip fare from baltimore to dallas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def vector(sentences):\n",
    "    # Load the spacy model: nlp\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "    # Calculate the length of sentences\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Calculate the dimensionality of nlp\n",
    "    embedding_dim = nlp.vocab.vectors_length\n",
    "    \n",
    "    # Initialize the array with zeros: X\n",
    "    X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "    # Iterate over the sentences\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        # Pass each each sentence to the nlp object to create a document\n",
    "        doc = nlp(sentence)\n",
    "        # Save the document's .vector attribute to the corresponding row in X\n",
    "        X[idx, :] = doc.vector\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07225148,  0.23085858, -0.05721947, ...,  0.04366079,\n",
       "        -0.11307659,  0.21412031],\n",
       "       [ 0.11721275,  0.04901224, -0.14363982, ..., -0.14155565,\n",
       "        -0.06796242,  0.18658884],\n",
       "       [ 0.13610677,  0.17966814, -0.05222185, ...,  0.04048143,\n",
       "        -0.16161631,  0.12550484],\n",
       "       ...,\n",
       "       [ 0.16177949,  0.0670125 ,  0.088523  , ..., -0.0717375 ,\n",
       "        -0.066895  ,  0.0520265 ],\n",
       "       [ 0.11427727,  0.11960033, -0.03754008, ..., -0.07084992,\n",
       "        -0.142048  ,  0.19235454],\n",
       "       [-0.00103583,  0.01718292, -0.04143599, ..., -0.06478167,\n",
       "        -0.04346119,  0.14688456]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what flights are available from pittsburgh to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>what is the arrival time in san francisco for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cheapest airfare from tacoma to orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  1   i want to fly from boston at 838 am and arriv...\n",
       "1  1   what flights are available from pittsburgh to...\n",
       "2  0   what is the arrival time in san francisco for...\n",
       "3  0            cheapest airfare from tacoma to orlando\n",
       "4  0   round trip fares from pittsburgh to philadelp..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis = pd.read_csv('atis/atis_intents.csv', header= None)\n",
    "atis[0] = atis[0].apply(lambda x: 1 if x == 'atis_flight' else 0)\n",
    "y = atis[0]\n",
    "atis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = atis[1].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vector(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 842 correctly out of 996 test examples\n"
     ]
    }
   ],
   "source": [
    "# Import SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a support vector classifier\n",
    "clf = SVC(C = 1, gamma = 'auto')\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "\n",
    "\n",
    "n_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test.values.tolist()[i]:\n",
    "        n_correct += 1\n",
    "\n",
    "print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using spaCy's entity recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': '2010', 'ORG': 'Google', 'PERSON': 'Mary'}\n",
      "{'DATE': '1999', 'ORG': 'MIT', 'PERSON': None}\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "# Define included_entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning roles using spaCy's parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_type(word):\n",
    "    _type = None\n",
    "    if word.text in colors:\n",
    "        _type = \"color\"\n",
    "    elif word.text in items:\n",
    "        _type = \"item\"\n",
    "    return _type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: jacket has color : red\n",
      "item: jeans has color : blue\n"
     ]
    }
   ],
   "source": [
    "# Create the document\n",
    "doc = nlp(\"let's see that jacket in red and some blue jeans\")\n",
    "colors = ['black', 'red', 'blue']\n",
    "items = ['shoes', 'handback', 'jacket', 'jeans']\n",
    "\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in word.ancestors:\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(parent) == \"item\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in doc:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"color\":\n",
    "            # Find the parent\n",
    "            item =  find_parent_item(word)\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "assign_colors(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasa NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"training_data.json\", 'r') as handle:\n",
    "#     parsed = json.load(handle)\n",
    "#     print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huiren/anaconda3/envs/spacy/lib/python3.7/site-packages/rasa_nlu/__init__.py:12: UserWarning: The 'rasa_nlu' package has been renamed. You should change your imports to use 'rasa.nlu' instead.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Create args dictionary\n",
    "args = {\"pipeline\": \"pretrained_embeddings_spacy\"}\n",
    "\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUModelConfig(args)\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Load the training data\n",
    "training_data = load_data(\"training_data.json\")\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Test the interpreter\n",
    "# print(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-efficient entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = [\n",
    "#     \"nlp_spacy\",\n",
    "#     \"tokenizer_spacy\",\n",
    "#     \"ner_crf\"\n",
    "# ]\n",
    "\n",
    "# # Create a config that uses this pipeline\n",
    "# config = RasaNLUModelConfig({'pipeline': pipeline})\n",
    "\n",
    "# # Create a trainer that uses this config\n",
    "# trainer = Trainer(config)\n",
    "\n",
    "# # Create an interpreter by training the model\n",
    "# interpreter = trainer.train(training_data)\n",
    "\n",
    "# # Parse some messages\n",
    "# print(interpreter.parse(\"show me Chinese food in the centre of town\"))\n",
    "# print(interpreter.parse(\"I want an Indian restaurant in the west\"))\n",
    "# print(interpreter.parse(\"are there any good pizza places in the center?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a virtual assistant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL statements in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Grand Hotel', 'hi', 'south', 5)]\n"
     ]
    }
   ],
   "source": [
    "# Import sqlite3\n",
    "import sqlite3\n",
    "\n",
    "# Open connection to DB\n",
    "conn = sqlite3.connect('hotels.db')\n",
    "\n",
    "# Create a cursor\n",
    "c = conn.cursor()\n",
    "\n",
    "# Define area and price\n",
    "area, price = \"south\", \"hi\"\n",
    "t = (area, price)\n",
    "\n",
    "# Execute the query\n",
    "c.execute('SELECT * FROM hotels WHERE area=? AND price=?', t)\n",
    "\n",
    "# Print the results\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating queries from parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_hotels()\n",
    "def find_hotels(params):\n",
    "    # Create the base query\n",
    "    query = 'SELECT * FROM hotels'\n",
    "    # Add filter clauses for each of the parameters\n",
    "    if len(params) > 0:\n",
    "        filters = [\"{}=?\".format(k) for k in params]\n",
    "        query += \" WHERE \" + \" and \".join(filters)\n",
    "    # Create the tuple of values\n",
    "    t = tuple(params.values())\n",
    "    \n",
    "    # Open connection to DB\n",
    "    conn = sqlite3.connect(\"hotels.db\")\n",
    "    # Create a cursor\n",
    "    c = conn.cursor()\n",
    "    # Execute the query\n",
    "    c.execute(query, t)\n",
    "    # Return the results\n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your custom function to find hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Cozy Cottage', 'lo', 'south', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary of column names and values\n",
    "params = {'area': 'south', 'price':'lo'}\n",
    "\n",
    "# Find the hotels that match the parameters\n",
    "print(find_hotels(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SQL from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grand Hotel is a great hotel!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = [\"I'm sorry :( I couldn't find anything like that\", '{} is a great hotel!', '{} or {} would work!', '{} is one option, but I know others too :)']\n",
    "# Define respond()\n",
    "def respond(entities):\n",
    "    # Extract the entities\n",
    "#     entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Initialize an empty params dictionary\n",
    "    params = {}\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find hotels that match the dictionary\n",
    "    results = find_hotels(params)\n",
    "    # Get the names of the hotels and index of the response\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Select the nth element of the responses array\n",
    "    return responses[n].format(*names)\n",
    "\n",
    "# Test the respond() function\n",
    "# respond(\"I want an expensive hotel in the south of town\")\n",
    "respond([{'entity': 'price', 'processors': ['ner_synonyms'], 'value': 'hi', 'start': 10, 'extractor': 'ner_crf', 'end': 19}, {'entity': 'area', 'start': 33, 'value': 'south', 'extractor': 'ner_crf', 'end': 38}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining your search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Ben's BnB is a great hotel!\", {'price': 'hi', 'area': 'north'})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a respond function, taking the message and existing params as input\n",
    "def respond(entities, params):\n",
    "    # Extract the entities\n",
    "#     entities = interpreter.parse(message)['entities']\n",
    "\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find the hotels\n",
    "    results = find_hotels(params)\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results), 3)\n",
    "    # Return the appropriate response\n",
    "    return responses[n].format(*names), params\n",
    "\n",
    "# Initialize params dictionary\n",
    "params = {}\n",
    "\n",
    "respond([{'entity': 'price', 'processors': ['ner_synonyms'], 'value': 'hi', 'start': 10, 'extractor': 'ner_crf', 'end': 19}, {'entity': 'area', 'start': 7, 'value': 'north', 'extractor': 'ner_crf', 'end': 12}], params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define negated_ents()\n",
    "def negated_ents(phrase):\n",
    "    # Extract the entities using keyword matching\n",
    "    ents = [e for e in [\"south\", \"north\"] if e in phrase]\n",
    "    # Find the index of the final character of each entity\n",
    "    ends = sorted([phrase.index(e) + len(e) for e in ents])\n",
    "    # Initialise a list to store sentence chunks\n",
    "    chunks = []\n",
    "    # Take slices of the sentence up to and including each entitiy\n",
    "    start = 0\n",
    "    for end in ends:\n",
    "        chunks.append(phrase[start:end])\n",
    "        start = end\n",
    "    result = {}\n",
    "    # Iterate over the chunks and look for entities\n",
    "    for chunk in chunks:\n",
    "        for ent in ents:\n",
    "            if ent in chunk:\n",
    "                # If the entity contains a negation, assign the key to be False\n",
    "                if \"not\" in chunk or \"n't\" in chunk:\n",
    "                    result[ent] = False\n",
    "                else:\n",
    "                    result[ent] = True\n",
    "    return result  \n",
    "\n",
    "# Check that the entities are correctly assigned as True or False\n",
    "tests = [(\"no I don't want to be in the south\", {'south': False}), ('no it should be in the south', {'south': True}), ('no in the south not the north', {'south': True, 'north': False}), ('not north', {'north': False})]\n",
    "for test in tests:\n",
    "    print(negated_ents(test[0]) == test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'south': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negated_ents(\"no I don't want to be in the south\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with excluded slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hotels(params, neg_params):\n",
    "    query = 'SELECT * FROM hotels'\n",
    "    if len(params) > 0:\n",
    "        filters = [\"{}=?\".format(k) for k in params] +                  [\"{}!=?\".format(k) for k in neg_params] \n",
    "        query += \" WHERE \" + \" and \".join(filters)\n",
    "    t = tuple(params.values())\n",
    "    \n",
    "    # open connection to DB\n",
    "    conn = sqlite3.connect('hotels.db')\n",
    "    # create a cursor\n",
    "    c = conn.cursor()\n",
    "    c.execute(query, t)\n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negated_ents(phrase, ent_vals):\n",
    "    ents = [e for e in ent_vals if e in phrase]\n",
    "    ends = sorted([phrase.index(e)+len(e) for e in ents])\n",
    "    start = 0\n",
    "    chunks = []\n",
    "    for end in ends:\n",
    "        chunks.append(phrase[start:end])\n",
    "        start = end\n",
    "    result = {}\n",
    "    for chunk in chunks:\n",
    "        for ent in ents:\n",
    "            if ent in chunk:\n",
    "                if \"not\" in chunk or \"n't\" in chunk:\n",
    "                    result[ent] = False\n",
    "                else:\n",
    "                    result[ent] = True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: I want a cheap hotel\n",
      "BOT: Cozy Cottage is a great hotel!\n",
      "USER: but not in the north of town\n",
      "BOT: Hotel California or Ben's BnB would work!\n"
     ]
    }
   ],
   "source": [
    "# Define the respond function\n",
    "def respond(message, entities, params, neg_params):\n",
    "    # Extract the entities\n",
    "#     entities = interpreter.parse(message)[\"entities\"]\n",
    "    ent_vals = [e[\"value\"] for e in entities]\n",
    "    # Look for negated entities\n",
    "    negated = negated_ents(message, ent_vals)\n",
    "    for ent in entities:\n",
    "        if ent[\"value\"] in negated and negated[ent[\"value\"]]:\n",
    "            neg_params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "        else:\n",
    "            params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "    # Find the hotels\n",
    "    results = find_hotels(params, neg_params)\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Return the correct response\n",
    "    return responses[n].format(*names), params, neg_params\n",
    "\n",
    "message = \"I want a cheap hotel\"\n",
    "entities = [{'entity': 'price', 'processors': ['ner_synonyms'], 'value': 'lo', 'start': 9, 'extractor': 'ner_crf', 'end': 14}]\n",
    "params = {}\n",
    "neg_params = {}\n",
    "\n",
    "response, params, neg_params = respond(message, entities, params, neg_params)\n",
    "print(\"USER: {}\".format(message))\n",
    "print(\"BOT: {}\".format(response))\n",
    "\n",
    "message = \"but not in the north of town\"\n",
    "entities = [{'entity': 'area', 'start': 15, 'value': 'north', 'extractor': 'ner_crf', 'end': 20}]\n",
    "params = {}\n",
    "neg_params = {}\n",
    "\n",
    "response, params, neg_params = respond(message, entities, params, neg_params)\n",
    "print(\"USER: {}\".format(message))\n",
    "print(\"BOT: {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret = {\n",
    "    \"I'd like to become a professional dancer\": 'none',\n",
    "    \"well then I'd like to order some coffee\": 'order',\n",
    "    \"my favourite animal is a zebra\": 'none',\n",
    "    \"kenyan\": 'specify_coffee'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(policy, state, message):\n",
    "    (new_state, response) = policy[(state, interpret[message])]\n",
    "    return new_state, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(policy, state, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    new_state, response = respond(policy, state, message)\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : I'd like to become a professional dancer\n",
      "BOT : I'm sorry - I'm not sure how to help you\n",
      "USER : well then I'd like to order some coffee\n",
      "BOT : ok, Colombian or Kenyan?\n",
      "USER : my favourite animal is a zebra\n",
      "BOT : I'm sorry - would you like Colombian or Kenyan?\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n"
     ]
    }
   ],
   "source": [
    "# Define the INIT state\n",
    "INIT = 0\n",
    "\n",
    "# Define the CHOOSE_COFFEE state\n",
    "CHOOSE_COFFEE = 1\n",
    "\n",
    "# Define the ORDERED state\n",
    "ORDERED = 2\n",
    "\n",
    "# Define the policy rules\n",
    "policy = {\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Colombian or Kenyan?\"),\n",
    "    (INIT, \"none\"): (INIT, \"I'm sorry - I'm not sure how to help you\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"none\"): (CHOOSE_COFFEE, \"I'm sorry - would you like Colombian or Kenyan?\"),\n",
    "}\n",
    "\n",
    "# Create the list of messages\n",
    "messages = [\n",
    "    \"I'd like to become a professional dancer\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"my favourite animal is a zebra\",\n",
    "    \"kenyan\"\n",
    "]\n",
    "\n",
    "# Call send_message() for each message\n",
    "state = INIT\n",
    "for message in messages:    \n",
    "    state = send_message(policy, state, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking contextual questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret = {    \n",
    "    \"what can you do for me?\": 'ask_explanation',\n",
    "    \"well then I'd like to order some coffee\": 'order',\n",
    "    \"what do you mean by that?\": 'ask_explanation',\n",
    "    \"kenyan\": 'specify_coffee'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(state, message):\n",
    "    (new_state, response) = policy_rules[(state, interpret[message])]\n",
    "    return new_state, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(state, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    new_state, response = respond(state, message)\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : what can you do for me?\n",
      "BOT : I'm a bot to help you order coffee beans\n",
      "USER : well then I'd like to order some coffee\n",
      "BOT : ok, Colombian or Kenyan?\n",
      "USER : what do you mean by that?\n",
      "BOT : We have two kinds of coffee beans - the Kenyan ones make a slightly sweeter coffee, and cost $6. The Brazilian beans make a nutty coffee and cost $5.\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n"
     ]
    }
   ],
   "source": [
    "# Define the states\n",
    "INIT=0 \n",
    "CHOOSE_COFFEE=1\n",
    "ORDERED=2\n",
    "\n",
    "# Define the policy rules dictionary\n",
    "policy_rules = {\n",
    "    (INIT, \"ask_explanation\"): (INIT, \"I'm a bot to help you order coffee beans\"),\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Colombian or Kenyan?\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"ask_explanation\"): (CHOOSE_COFFEE, \"We have two kinds of coffee beans - the Kenyan ones make a slightly sweeter coffee, and cost $6. The Brazilian beans make a nutty coffee and cost $5.\")    \n",
    "}\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    for msg in messages:\n",
    "        state = send_message(state, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"what can you do for me?\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"what do you mean by that?\",\n",
    "    \"kenyan\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret = {\n",
    "    \"I want a mid range hotel\": {'entities': [], 'text': 'I want a mid range hotel', 'intent': {'confidence': 0.0, 'name': ''}}, \n",
    "    \"no that doesn't work for me\": {'entities': [], 'text': \"no that doesn't work for me\", 'intent': {'confidence': 0.0, 'name': 'deny'}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hotels(params, excluded):\n",
    "    query = 'SELECT * FROM hotels'\n",
    "    if len(params) > 0:\n",
    "        filters = [\"{}=?\".format(k) for k in params] + [\"name!='?'\".format(k) for k in excluded] \n",
    "        query += \" WHERE \" + \" and \".join(filters)\n",
    "    t = tuple(params.values())\n",
    "    \n",
    "    # open connection to DB\n",
    "    conn = sqlite3.connect('hotels.db')\n",
    "    # create a cursor\n",
    "    c = conn.cursor()\n",
    "    c.execute(query, t)\n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: I want a mid range hotel\n",
      "BOT: Hotel for Dogs is one option, but I know others too :)\n",
      "USER: no that doesn't work for me\n",
      "BOT: Grand Hotel is one option, but I know others too :)\n"
     ]
    }
   ],
   "source": [
    "# Define respond()\n",
    "def respond(message, params, prev_suggestions, excluded):\n",
    "    # Interpret the message\n",
    "    parse_data = interpret[message]\n",
    "    # Extract the intent\n",
    "    intent = parse_data['intent']['name']\n",
    "    # Extract the entities\n",
    "    entities = parse_data['entities']\n",
    "    # Add the suggestion to the excluded list if intent is \"deny\"\n",
    "    if intent == \"deny\":\n",
    "        excluded.extend(prev_suggestions)\n",
    "    # Fill the dictionary with entities\t\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "    # Find matching hotels\n",
    "    results = [r for r in find_hotels(params, excluded) if r[0] not in excluded]\n",
    "    # Extract the suggestions\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results), 3)\n",
    "    suggestions = names[:2]\n",
    "    return responses[n].format(*names), params, suggestions, excluded\n",
    "\n",
    "# Initialize the empty dictionary and lists\n",
    "params, suggestions, excluded = {}, [], []\n",
    "\n",
    "# Send the messages\n",
    "for message in [\"I want a mid range hotel\", \"no that doesn't work for me\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params, suggestions, excluded = respond(message, params, suggestions, excluded)\n",
    "    print(\"BOT: {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending actions I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define policy()\n",
    "def policy(intent):\n",
    "    # Return \"do_pending\" if the intent is \"affirm\"\n",
    "    if intent == \"affirm\":\n",
    "        return \"do_pending\", None\n",
    "    # Return \"Ok\" if the intent is \"deny\"\n",
    "    if intent == \"deny\":\n",
    "        return \"Ok\", None\n",
    "    if intent == \"order\":\n",
    "        return \"Unfortunately, the Kenyan coffee is currently out of stock, would you like to order the Brazilian beans?\", \"Alright, I've ordered that for you!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending actions II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret = {\n",
    "    \"I'd like to order some coffee\": 'order',\n",
    "    \"ok yes please\": 'affirm'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : I'd like to order some coffee\n",
      "BOT : Unfortunately, the Kenyan coffee is currently out of stock, would you like to order the Brazilian beans?\n",
      "USER : ok yes please\n",
      "BOT : Alright, I've ordered that for you!\n"
     ]
    }
   ],
   "source": [
    "# Define send_message()\n",
    "def send_message(pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    action, pending_action = policy(interpret[message])\n",
    "    if action == \"do_pending\" and pending is not None:\n",
    "        print(\"BOT : {}\".format(pending))\n",
    "    else:\n",
    "        print(\"BOT : {}\".format(action))\n",
    "    return pending_action\n",
    "    \n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        pending = send_message(pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"ok yes please\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending state transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret = {\n",
    "    \"I'd like to order some coffee\": 'order',\n",
    "    \"555-1234\": 'number',\n",
    "    \"kenyan\" : 'specify_coffee'   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(state, pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    new_state, response, pending_state = policy_rules[(state, interpret[message])]\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    if pending is not None:\n",
    "        new_state, response, pending_state = policy_rules[pending]\n",
    "        print(\"BOT : {}\".format(response))        \n",
    "    if pending_state is not None:\n",
    "        pending = (pending_state, interpret[message])\n",
    "    return new_state, pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : I'd like to order some coffee\n",
      "BOT : you'll have to log in first, what's your phone number?\n",
      "USER : 555-1234\n",
      "BOT : perfect, welcome back!\n",
      "BOT : would you like Colombian or Kenyan?\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n",
      "BOT : would you like Colombian or Kenyan?\n"
     ]
    }
   ],
   "source": [
    "# Define the states\n",
    "INIT=0\n",
    "AUTHED=1\n",
    "CHOOSE_COFFEE=2\n",
    "ORDERED=3\n",
    "\n",
    "# Define the policy rules\n",
    "policy_rules = {\n",
    "    (INIT, \"order\"): (INIT, \"you'll have to log in first, what's your phone number?\", AUTHED),\n",
    "    (INIT, \"number\"): (AUTHED, \"perfect, welcome back!\", None),\n",
    "    (AUTHED, \"order\"): (CHOOSE_COFFEE, \"would you like Colombian or Kenyan?\", None),    \n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\", None)\n",
    "}\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"555-1234\",\n",
    "    \"kenyan\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chitchat_response()\n",
    "def chitchat_response(message):\n",
    "    # Call match_rule()\n",
    "    response, phrase = match_rule(eliza_rules, message)\n",
    "    # Return none if response is \"default\"\n",
    "    if response == \"default\":\n",
    "        return None\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns of phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Calculate the response\n",
    "        response = response.format(phrase)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret = {\n",
    "    \"I'd like to order some coffee\": 'order',\n",
    "    \"555-12345\": 'number',\n",
    "    \"do you remember when I ordered 1000 kilos by accident?\": 'order',\n",
    "    \"kenyan\": 'specify_coffee'   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliza_rules = {'do you remember (.*)': ['Did you think I would forget {0}', \"Why haven't you been able to forget {0}\", 'What about {0}', 'Yes .. and?'], 'I want (.*)': ['What would it mean if you got {0}', 'Why do you want {0}', \"What's stopping you from getting {0}\"], 'if (.*)': [\"Do you really think it's likely that {0}\", 'Do you wish that {0}', 'What do you think about {0}', 'Really--if {0}'], 'do you think (.*)': ['if {0}? Absolutely.', 'No chance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : I'd like to order some coffee\n",
      "BOT : you'll have to log in first, what's your phone number?\n",
      "USER : 555-12345\n",
      "BOT : perfect, welcome back!\n",
      "BOT : would you like Colombian or Kenyan?\n",
      "USER : do you remember when I ordered 1000 kilos by accident?\n",
      "BOT : What about when i ordered 1000 kilos by accident?\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n"
     ]
    }
   ],
   "source": [
    "# Define send_message()\n",
    "def send_message(state, pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    response = chitchat_response(message)\n",
    "    if response is not None:\n",
    "        print(\"BOT : {}\".format(response))\n",
    "        return state, None\n",
    "    \n",
    "    # Calculate the new_state, response, and pending_state\n",
    "    new_state, response, pending_state = policy_rules[(state, interpret[message])]\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    if pending is not None:\n",
    "        new_state, response, pending_state = policy_rules[pending]\n",
    "        print(\"BOT : {}\".format(response))        \n",
    "    if pending_state is not None:\n",
    "        pending = (pending_state, interpret[message])\n",
    "    return new_state, pending\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"555-12345\",\n",
    "    \"do you remember when I ordered 1000 kilos by accident?\",\n",
    "    \"kenyan\"\n",
    "])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = {0.2: \"i'm gonna punch lenny in the back of the been a to the on the man to the mother and the father to simpson the father to with the marge in the for the like the fame to the been to the for my bart the don't was in the like the for the father the father a was the father been a say the been to me the do it and the father been to go. i want to the boy i can the from a man to be the for the been a like the father to make my bart of the father\", 0.5: \"i'm gonna punch lenny in the back of the kin't she change and i'm all better it and the was the fad a drivera it? what i want to did hey, he would you would in your bus who know is the like and this don't are for your this all for your manset the for it a man is on the see the will they want to know i'm are for one start of that and i got the better this is. it whoce and i don't are on the mater stop in the from a for the be your mileat\", 1.2: \"i'm gonna punch lenny in the back of the burear prespe-nakes, 'lisa to isn't that godios.and when be the bowniday' would lochs meine, mind crikvin' suhle ovotaci!..... hey, a poielyfd othe flancer, this in are rightplouten of of we doll hurrs, truelturone? rake inswaydan justy!we scrikent.ow.. by back hous, smadge, the lighel irely.yes, homer. wel'e esasmoy ryelalrs all wronencay...... nank. i wenth makedyk. come on help cerzind, now, n\", 1.0: \"i'm gonna punch lenny in the back of the to to macks how screath. firl done we wouldn't wil that kill. of this torshmobote since, i know i ord did, can give crika of sintenn prescoam.whover my me after may? there's right. that up. there's ruining isay.oh.solls.nan'h those off point chuncing car your anal medion.hey, are exallies a off while bea dolk of sure, hello, no in her, we'll rundems... i'm eventy taving me to too the letberngonce\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text(seed, temperature):\n",
    "    return generated[temperature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating text with riskiness : 0.2\n",
      "\n",
      "i'm gonna punch lenny in the back of the been a to the on the man to the mother and the father to simpson the father to with the marge in the for the like the fame to the been to the for my bart the don't was in the like the for the father the father a was the father been a say the been to me the do it and the father been to go. i want to the boy i can the from a man to be the for the been a like the father to make my bart of the father\n",
      "\n",
      "Generating text with riskiness : 0.5\n",
      "\n",
      "i'm gonna punch lenny in the back of the kin't she change and i'm all better it and the was the fad a drivera it? what i want to did hey, he would you would in your bus who know is the like and this don't are for your this all for your manset the for it a man is on the see the will they want to know i'm are for one start of that and i got the better this is. it whoce and i don't are on the mater stop in the from a for the be your mileat\n",
      "\n",
      "Generating text with riskiness : 1.0\n",
      "\n",
      "i'm gonna punch lenny in the back of the to to macks how screath. firl done we wouldn't wil that kill. of this torshmobote since, i know i ord did, can give crika of sintenn prescoam.whover my me after may? there's right. that up. there's ruining isay.oh.solls.nan'h those off point chuncing car your anal medion.hey, are exallies a off while bea dolk of sure, hello, no in her, we'll rundems... i'm eventy taving me to too the letberngonce\n",
      "\n",
      "Generating text with riskiness : 1.2\n",
      "\n",
      "i'm gonna punch lenny in the back of the burear prespe-nakes, 'lisa to isn't that godios.and when be the bowniday' would lochs meine, mind crikvin' suhle ovotaci!..... hey, a poielyfd othe flancer, this in are rightplouten of of we doll hurrs, truelturone? rake inswaydan justy!we scrikent.ow.. by back hous, smadge, the lighel irely.yes, homer. wel'e esasmoy ryelalrs all wronencay...... nank. i wenth makedyk. come on help cerzind, now, n\n"
     ]
    }
   ],
   "source": [
    "# Feed the seed text into the neural network\n",
    "seed = \"i'm gonna punch lenny in the back of the\"\n",
    "\n",
    "# Iterate over the different temperature values\n",
    "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(\"\\nGenerating text with riskiness : {}\\n\".format(temperature))\n",
    "    # Call the sample_text function\n",
    "    print(sample_text(seed, temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
